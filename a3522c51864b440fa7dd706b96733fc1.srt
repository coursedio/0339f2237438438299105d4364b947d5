WEBVTT

1
00:00:00.005 --> 00:00:03.004
- [Instructor] The Open AI organization is notable

2
00:00:03.004 --> 00:00:05.002
not just by their track record

3
00:00:05.002 --> 00:00:08.000
in releasing groundbreaking AI solutions,

4
00:00:08.000 --> 00:00:09.004
but by its published mission

5
00:00:09.004 --> 00:00:12.006
to support the use of artificial general intelligence,

6
00:00:12.006 --> 00:00:16.001
AGI for the benefit of all humanity.

7
00:00:16.001 --> 00:00:19.002
Note, though that AGI is aspirational

8
00:00:19.002 --> 00:00:21.003
and doesn't yet exist.

9
00:00:21.003 --> 00:00:24.003
That said, it's clearly the pursuit of many

10
00:00:24.003 --> 00:00:27.001
and the AI capabilities we are experiencing today

11
00:00:27.001 --> 00:00:30.003
are likely points along the way.

12
00:00:30.003 --> 00:00:33.001
The subject of how we humanely approach AI

13
00:00:33.001 --> 00:00:36.000
is not novel to OpenAI.

14
00:00:36.000 --> 00:00:37.006
The ethical use of AI,

15
00:00:37.006 --> 00:00:41.004
now often refer to as responsible AI is concerned

16
00:00:41.004 --> 00:00:43.006
with ensuring the development and use of AI

17
00:00:43.006 --> 00:00:45.009
with positive intentions and fairness

18
00:00:45.009 --> 00:00:48.000
to all that it impacts.

19
00:00:48.000 --> 00:00:51.002
It's about considering safety, security,

20
00:00:51.002 --> 00:00:56.000
care and accountability in AI creation and use.

21
00:00:56.000 --> 00:00:58.005
Stakeholders include business leaders,

22
00:00:58.005 --> 00:01:01.001
university researchers, and governments.

23
00:01:01.001 --> 00:01:04.008
For example, the topic of AI regulation and legislation

24
00:01:04.008 --> 00:01:07.005
is firmly part of global discourse.

25
00:01:07.005 --> 00:01:09.009
In the United Arab Emirates, for instance,

26
00:01:09.009 --> 00:01:11.007
there's a minister of AI

27
00:01:11.007 --> 00:01:14.006
whose purview includes the ethics of AI.

28
00:01:14.006 --> 00:01:17.009
How to move forward responsibly with AI is a topic

29
00:01:17.009 --> 00:01:21.007
being discussed in government buildings across the world.

30
00:01:21.007 --> 00:01:25.002
AI ethics include areas such as bias,

31
00:01:25.002 --> 00:01:28.002
weaponization, morality,

32
00:01:28.002 --> 00:01:32.001
robot autonomy, and liability.

33
00:01:32.001 --> 00:01:34.007
Each of these are beyond the scope of this course

34
00:01:34.007 --> 00:01:38.006
but depending on your interest may warrant further research,

35
00:01:38.006 --> 00:01:41.006
including delving into the related AI courses

36
00:01:41.006 --> 00:01:45.002
in the LinkedIn Learning library.

37
00:01:45.002 --> 00:01:48.005
Now, let's turn our attention back to OpenAI.

38
00:01:48.005 --> 00:01:52.001
In 2019, in an attempt to capture the principles

39
00:01:52.001 --> 00:01:54.000
by which they execute their mission

40
00:01:54.000 --> 00:01:57.001
of supporting the development and deployment of AGI

41
00:01:57.001 --> 00:02:02.003
for the benefit of humanity, OpenAI published a charter.

42
00:02:02.003 --> 00:02:06.002
The document found on their website is a codified expression

43
00:02:06.002 --> 00:02:07.003
of their strategy

44
00:02:07.003 --> 00:02:09.006
and was developed with feedback from inside

45
00:02:09.006 --> 00:02:12.000
and outside the organization.

46
00:02:12.000 --> 00:02:13.002
It's an important artifact

47
00:02:13.002 --> 00:02:16.002
that goes beyond communicating their values.

48
00:02:16.002 --> 00:02:19.002
It can provide inspiration and guidance to others

49
00:02:19.002 --> 00:02:22.004
who are looking to adopt similar approaches.

50
00:02:22.004 --> 00:02:25.004
While I encourage everyone to read the charter

51
00:02:25.004 --> 00:02:28.002
and I include a link on the screen,

52
00:02:28.002 --> 00:02:33.001
here is a brief overview of the main four principles.

53
00:02:33.001 --> 00:02:38.000
First, the benefits of AGI should be enjoyed by everyone.

54
00:02:38.000 --> 00:02:40.003
The focus should remain on the advantages

55
00:02:40.003 --> 00:02:42.005
to all of humanity.

56
00:02:42.005 --> 00:02:46.007
Second, AGI Research and development should be safe.

57
00:02:46.007 --> 00:02:49.004
In addition and particularly notable,

58
00:02:49.004 --> 00:02:52.006
if an AGI project emerges from a competitor

59
00:02:52.006 --> 00:02:54.009
that could incentivize speed to market

60
00:02:54.009 --> 00:02:59.001
at the cost of safety, OpenAI will not compete

61
00:02:59.001 --> 00:03:03.000
and will instead partner and assist the competitor.

62
00:03:03.000 --> 00:03:05.004
Third, OpenAI will strive

63
00:03:05.004 --> 00:03:07.006
to demonstrate technical leadership

64
00:03:07.006 --> 00:03:12.009
in order to amplify the benefits of AI and AGI.

65
00:03:12.009 --> 00:03:15.004
Finally, they're committed to broad collaboration

66
00:03:15.004 --> 00:03:19.003
with research and policy institutions across the world.

67
00:03:19.003 --> 00:03:20.004
Central to this is

68
00:03:20.004 --> 00:03:23.009
sharing as much of their research as is reasonable.

69
00:03:23.009 --> 00:03:25.006
They want to participate in the building

70
00:03:25.006 --> 00:03:28.005
of a strong AGI community across the planet

71
00:03:28.005 --> 00:03:33.003
to ensure that AGI challenges are addressed.

72
00:03:33.003 --> 00:03:35.006
I'm sure you'll agree that these are admirable

73
00:03:35.006 --> 00:03:37.008
and lofty principles.

74
00:03:37.008 --> 00:03:40.005
However, the degree to which they can be met

75
00:03:40.005 --> 00:03:44.000
over the long term and whether OpenAI will adhere to them

76
00:03:44.000 --> 00:03:45.009
are unknown at this time.

77
00:03:45.009 --> 00:03:49.009
We'll let others discuss and debate that.

78
00:03:49.009 --> 00:03:52.005
Perhaps the charter's most enduring quality

79
00:03:52.005 --> 00:03:56.006
is that it can inspire others to create a positive roadmap

80
00:03:56.006 --> 00:03:59.000
for their AI efforts.

81
00:03:59.000 --> 00:04:01.008
After all, with the stakes being so high,

82
00:04:01.008 --> 00:04:03.000
we should be motivated

83
00:04:03.000 --> 00:04:06.005
to reduce the potential risks inherent to a world

84
00:04:06.005 --> 00:04:09.003
driven by AI.

85
00:04:09.003 --> 00:04:11.006
Now, before proceeding to the next video,

86
00:04:11.006 --> 00:04:15.000
as a suggestion, pause for a few moments to consider

87
00:04:15.000 --> 00:04:18.006
and write down what principles you think would be important

88
00:04:18.006 --> 00:04:22.006
for your organization in its pursuit of AI.
